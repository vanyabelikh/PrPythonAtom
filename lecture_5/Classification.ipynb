{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#импортируем необходимые модули\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(y_hat, y, thresh):\n",
    "    #TODO recall\n",
    "    \n",
    "def precision(y_hat, y, thresh):\n",
    "    #TODO\n",
    "    \n",
    "def accuracy(y_hat, y, thresh):\n",
    "    #TODO\n",
    "    \n",
    "def f1(y_hat, y, thresh):\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Test {} passed\".format(i))\n",
    "    y_hat = np.random.random(30)\n",
    "    y = np.random.random(30) > 0.7\n",
    "    thresh = np.random.random()\n",
    "    \n",
    "    assert abs(recall(y_hat, y, thresh) - recall_score(y_true=y, y_pred=y_hat > thresh)) < 0.1\n",
    "    assert abs(precision(y_hat, y, thresh) - precision_score(y_true=y, y_pred=y_hat > thresh)) < 0.1\n",
    "    assert abs(accuracy(y_hat, y, thresh) - accuracy_score(y_true=y, y_pred=y_hat > thresh)) < 0.1\n",
    "    assert abs(f1(y_hat, y, thresh) - f1_score(y_true=y, y_pred=y_hat > thresh)) < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = #TODO предсказания, чтобы выбить recall 0.9 плохим классификатором\n",
    "y = #TODO метки, чтобы выбить recall 0.9 плохим классификатором\n",
    "t = #TODO порог, чтобы выбить recall 0.9 плохим классификатором\n",
    "\n",
    "assert recall(y_hat, y, t) > 0.9\n",
    "\n",
    "y_hat = #TODO предсказания, чтобы выбить precision 0.9 плохим классификатором\n",
    "y = #TODO метки, чтобы выбить precision 0.9 плохим классификатором\n",
    "t = #TODO порог, чтобы выбить precision 0.9 плохим классификатором\n",
    "\n",
    "assert precision(y_hat, y, t) > 0.9\n",
    "\n",
    "y_hat = #TODO предсказания, чтобы выбить accuracy 0.9 плохим классификатором\n",
    "y = #TODO метки, чтобы выбить accuracy 0.9 плохим классификатором\n",
    "t = #TODO порог, чтобы выбить accuracy 0.9 плохим классификатором\n",
    "\n",
    "assert accuracy(y_hat, y, t) > 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция потерь для логистической регрессии (из материалов курса по нейронным сетям)\n",
    "\n",
    "Давайте получим функцию потерь аналогичным образом, как мы это сделали с линейной регрессией.\n",
    "\n",
    "\n",
    "логарифм правдоподобия\n",
    "$$\n",
    "\\large \n",
    "\\begin{array}{rcl} \n",
    "    \\log P\\left(\\vec{y} \\mid X, \\vec{w}\\right) \n",
    "        &=& \\log \\prod_{i=1}^{\\ell} P\\left(y = y_i \\mid \\vec{x_i}, \\vec{w}\\right) \\\\ \n",
    "        &=& \\log \\prod_{i=1}^{\\ell} \\sigma(y_i\\vec{w}^T\\vec{x_i}) \\\\ \n",
    "        &=& \\sum_{i=1}^{\\ell} \\log \\sigma(y_i\\vec{w}^T\\vec{x_i}) \\\\ \n",
    "        &=& \\sum_{i=1}^{\\ell} \\log \\frac{1}{1 + \\exp^{-y_i\\vec{w}^T\\vec{x_i}}} \\\\ \n",
    "        &=& - \\sum_{i=1}^{\\ell} \\log (1 + \\exp^{-y_i\\vec{w}^T\\vec{x_i}}) \n",
    "\\end{array}\n",
    "$$\n",
    "который и будем оптимизировать. \n",
    "\n",
    "Данная функция потерь \n",
    "$$\n",
    "\\large L(\\vec{x},\\vec{y},\\vec{w}) = \\sum_{i=1}^{\\ell} \\log (1 + \\exp^{-y_i\\vec{w}^T\\vec{x_i}})\n",
    "$$\n",
    "называется логистичской функцией потерь или сокращенно logloss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дано:\n",
    "- X - обучающее множество\n",
    "- Y - метки классов для обучающего множества\n",
    "- $\\eta$ - скорость обучения\n",
    "\n",
    "Алгоритм:\n",
    "1. инициализируем $\\vec{w}_0$ небольшими случайными значениями\n",
    "2. выбираем случайный объект $x_i$ с меткой $y_i$\n",
    "3. обновляем веса $ \\vec{w}_{t+1} = \\vec{w}_{t} - \\eta \\nabla L $\n",
    "4. если условие остановки не выполнело, возвращаемся к шагу 2\n",
    "\n",
    "Выпишем градиент функции потерь:\n",
    "$$\n",
    "    \\nabla L = \\left\\{ - \\frac{y_i \\vec{x_i} }  { 1 + \\exp^{y_i\\vec{w}^T\\vec{x_i}} } + \\lambda \\vec{w} \\right\\} \n",
    "$$\n",
    "\n",
    "На практике, в качестве условия остановки, часто используют изменение функции потерь на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "selector = iris.target != 0 # ограничемся только двумя классами\n",
    "X = iris.data[:, [1,3]][selector]  # и двумя переменными\n",
    "y = iris.target[selector]\n",
    "y[y==2] = 0 # конвертируем метки классов к 1/-1\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X[:80]\n",
    "X_test = X[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polytrans = PolynomialFeatures(3)\n",
    "X_train = polytrans.fit_transform(X_train)\n",
    "X_test = polytrans.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_1 = #TODO ОБучить логистическую регрессию на train с C=0.1\n",
    "pred_1 = #TODO Предсказать логистической регрессией на трейне\n",
    "pred_test = #TODO Предсказать логистической регрессией на тесте\n",
    "#TODO Сранивть метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO обучим логистическую регрессию с разными C и посмотрим как меняются метрики на трейне и на тесте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример текстовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import grid_search\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('products_sentiment_train.tsv', sep='\\t', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer = PorterStemmer()\n",
    "for i in range(0,len(data)):\n",
    "    arr = data.iloc[i,0].split(' ')\n",
    "    data.iloc[i,0] = ' '.join([str(porter_stemmer.stem(wordnet_lemmatizer.lemmatize(arr[i]))) for i in range(0, len(arr))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = [CountVectorizer(), TfidfVectorizer()]\n",
    "parameters_grid = {\n",
    "    'vectorizer__stop_words' : [nltk.corpus.stopwords.words('english'), 'english', None],\n",
    "    'vectorizer__ngram_range' : [(1,2), (1,3)],\n",
    "    'classifier__C':[0.25,0.5,1,2,5,10,15],\n",
    "    'classifier__class_weight':['balanced', None],\n",
    "    'classifier__max_iter':[70,100,200],\n",
    "    'classifier__penalty':['l2','l1']\n",
    "}\n",
    "for vect in vectors:\n",
    "        pipeline = Pipeline([('vectorizer', vect),('classifier',LogisticRegression())])\n",
    "        grid_cv = grid_search.GridSearchCV(pipeline, parameters_grid, n_jobs=-1, scoring = 'accuracy', cv = 3)\n",
    "        grid_cv.fit(data[0],data[1])\n",
    "        print('Classifier: logReg, vectoizer: ',vect,', best_score: ',grid_cv.best_score_, grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('products_sentiment_test.tsv', sep='\\t')\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(data_test)):\n",
    "    arr = data_test.iloc[i,1].split(' ')\n",
    "    data_test.iloc[i,1] = ' '.join([str(porter_stemmer.stem(wordnet_lemmatizer.lemmatize(arr[i].lower()))) for i in range(0, len(arr))])\n",
    "res = clf.predict(vectorizer.transform(data_test.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Appendix TODO together. Классификация отзывов о технике на русском"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
